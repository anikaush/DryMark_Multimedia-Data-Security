{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pywt\n",
    "from numpy.fft import fft2, ifft2\n",
    "from scipy.ndimage import filters\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ArgumentError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Extraction functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_single(im: np.ndarray,\n",
    "                   levels: int = 4,\n",
    "                   sigma: float = 5,\n",
    "                   wdft_sigma: float = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract noise residual from a single image\n",
    "    :param im: grayscale or color image, np.uint8\n",
    "    :param levels: number of wavelet decomposition levels\n",
    "    :param sigma: estimated noise power\n",
    "    :param wdft_sigma: estimated DFT noise power\n",
    "    :return: noise residual\n",
    "    \"\"\"\n",
    "\n",
    "    W = noise_extract(im, levels, sigma)\n",
    "    W = rgb2gray(W)\n",
    "    W = zero_mean_total(W)\n",
    "    W_std = W.std(ddof=1) if wdft_sigma == 0 else wdft_sigma\n",
    "    W = wiener_dft(W, W_std).astype(np.float32)\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def noise_extract(im: np.ndarray, levels: int = 4, sigma: float = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    NoiseExtract as from Binghamton toolbox.\n",
    "    :param im: grayscale or color image, np.uint8\n",
    "    :param levels: number of wavelet decomposition levels\n",
    "    :param sigma: estimated noise power\n",
    "    :return: noise residual\n",
    "    \"\"\"\n",
    "\n",
    "    assert (im.dtype == np.uint8)\n",
    "    assert (im.ndim in [2, 3])\n",
    "\n",
    "    im = im.astype(np.float32)\n",
    "\n",
    "    noise_var = sigma ** 2\n",
    "\n",
    "    if im.ndim == 2:\n",
    "        im.shape += (1,)\n",
    "\n",
    "    W = np.zeros(im.shape, np.float32)\n",
    "\n",
    "    for ch in range(im.shape[2]):\n",
    "\n",
    "        wlet = None\n",
    "        while wlet is None and levels > 0:\n",
    "            try:\n",
    "                wlet = pywt.wavedec2(im[:, :, ch], 'db4', level=levels)\n",
    "            except ValueError:\n",
    "                levels -= 1\n",
    "                wlet = None\n",
    "        if wlet is None:\n",
    "            raise ValueError('Impossible to compute Wavelet filtering for input size: {}'.format(im.shape))\n",
    "\n",
    "        wlet_details = wlet[1:]\n",
    "\n",
    "        wlet_details_filter = [None] * len(wlet_details)\n",
    "        # Cycle over Wavelet levels 1:levels-1\n",
    "        for wlet_level_idx, wlet_level in enumerate(wlet_details):\n",
    "            # Cycle over H,V,D components\n",
    "            level_coeff_filt = [None] * 3\n",
    "            for wlet_coeff_idx, wlet_coeff in enumerate(wlet_level):\n",
    "                level_coeff_filt[wlet_coeff_idx] = wiener_adaptive(wlet_coeff, noise_var)\n",
    "            wlet_details_filter[wlet_level_idx] = tuple(level_coeff_filt)\n",
    "\n",
    "        # Set filtered detail coefficients for Levels > 0 ---\n",
    "        wlet[1:] = wlet_details_filter\n",
    "\n",
    "        # Set to 0 all Level 0 approximation coefficients ---\n",
    "        wlet[0][...] = 0\n",
    "\n",
    "        # Invert wavelet transform ---\n",
    "        wrec = pywt.waverec2(wlet, 'db4')\n",
    "        try:\n",
    "            W[:, :, ch] = wrec\n",
    "        except ValueError:\n",
    "            W = np.zeros(wrec.shape[:2] + (im.shape[2],), np.float32)\n",
    "            W[:, :, ch] = wrec\n",
    "\n",
    "    if W.shape[2] == 1:\n",
    "        W.shape = W.shape[:2]\n",
    "\n",
    "    W = W[:im.shape[0], :im.shape[1]]\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def noise_extract_compact(args):\n",
    "    \"\"\"\n",
    "    Extract residual, multiplied by the image. Useful to save memory in multiprocessing operations\n",
    "    :param args: (im, levels, sigma), see noise_extract for usage\n",
    "    :return: residual, multiplied by the image\n",
    "    \"\"\"\n",
    "    w = noise_extract(*args)\n",
    "    im = args[0]\n",
    "    return (w * im / 255.).astype(np.float32)\n",
    "\n",
    "\n",
    "def extract_multiple_aligned(imgs: list, levels: int = 4, sigma: float = 5, processes: int = None,\n",
    "                             batch_size=cpu_count(), tqdm_str: str = '') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract PRNU from a list of images. Images are supposed to be the same size and properly oriented\n",
    "    :param tqdm_str: tqdm description (see tqdm documentation)\n",
    "    :param batch_size: number of parallel processed images\n",
    "    :param processes: number of parallel processes\n",
    "    :param imgs: list of images of size (H,W,Ch) and type np.uint8\n",
    "    :param levels: number of wavelet decomposition levels\n",
    "    :param sigma: estimated noise power\n",
    "    :return: PRNU\n",
    "    \"\"\"\n",
    "    assert (isinstance(imgs[0], np.ndarray))\n",
    "    assert (imgs[0].ndim == 3)\n",
    "    assert (imgs[0].dtype == np.uint8)\n",
    "\n",
    "    h, w, ch = imgs[0].shape\n",
    "\n",
    "    RPsum = np.zeros((h, w, ch), np.float32)\n",
    "    NN = np.zeros((h, w, ch), np.float32)\n",
    "\n",
    "    if processes is None or processes > 1:\n",
    "        args_list = []\n",
    "        for im in imgs:\n",
    "            args_list += [(im, levels, sigma)]\n",
    "        pool = Pool(processes=processes)\n",
    "\n",
    "        for batch_idx0 in tqdm(np.arange(start=0, step=batch_size, stop=len(imgs)), disable=tqdm_str == '',\n",
    "                               desc=(tqdm_str + ' (1/2)'), dynamic_ncols=True):\n",
    "            nni = pool.map(inten_sat_compact, args_list[batch_idx0:batch_idx0 + batch_size])\n",
    "            for ni in nni:\n",
    "                NN += ni\n",
    "            del nni\n",
    "\n",
    "        for batch_idx0 in tqdm(np.arange(start=0, step=batch_size, stop=len(imgs)), disable=tqdm_str == '',\n",
    "                               desc=(tqdm_str + ' (2/2)'), dynamic_ncols=True):\n",
    "            wi_list = pool.map(noise_extract_compact, args_list[batch_idx0:batch_idx0 + batch_size])\n",
    "            for wi in wi_list:\n",
    "                RPsum += wi\n",
    "            del wi_list\n",
    "\n",
    "        pool.close()\n",
    "\n",
    "    else:  # Single process\n",
    "        for im in tqdm(imgs, disable=tqdm_str is None, desc=tqdm_str, dynamic_ncols=True):\n",
    "            RPsum += noise_extract_compact((im, levels, sigma))\n",
    "            NN += (inten_scale(im) * saturation(im)) ** 2\n",
    "\n",
    "    K = RPsum / (NN + 1)\n",
    "    K = rgb2gray(K)\n",
    "    K = zero_mean_total(K)\n",
    "    K = wiener_dft(K, K.std(ddof=1)).astype(np.float32)\n",
    "\n",
    "    return K\n",
    "\n",
    "\n",
    "def cut_ctr(array: np.ndarray, sizes: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cut a multi-dimensional array at its center, according to sizes\n",
    "    :param array: multidimensional array\n",
    "    :param sizes: tuple of the same length as array.ndim\n",
    "    :return: multidimensional array, center cut\n",
    "    \"\"\"\n",
    "    array = array.copy()\n",
    "    if not (array.ndim == len(sizes)):\n",
    "        raise ArgumentError('array.ndim must be equal to len(sizes)')\n",
    "    for axis in range(array.ndim):\n",
    "        axis_target_size = sizes[axis]\n",
    "        axis_original_size = array.shape[axis]\n",
    "        if axis_target_size > axis_original_size:\n",
    "            raise ValueError(\n",
    "                'Can\\'t have target size {} for axis {} with original size {}'.format(axis_target_size, axis,\n",
    "                                                                                      axis_original_size))\n",
    "        elif axis_target_size < axis_original_size:\n",
    "            axis_start_idx = (axis_original_size - axis_target_size) // 2\n",
    "            axis_end_idx = axis_start_idx + axis_target_size\n",
    "            array = np.take(array, np.arange(axis_start_idx, axis_end_idx), axis)\n",
    "    return array\n",
    "\n",
    "\n",
    "def wiener_dft(im: np.ndarray, sigma: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adaptive Wiener filter applied to the 2D FFT of the image\n",
    "    :param im: multidimensional array\n",
    "    :param sigma: estimated noise power\n",
    "    :return: filtered version of input im\n",
    "    \"\"\"\n",
    "    noise_var = sigma ** 2\n",
    "    h, w = im.shape\n",
    "\n",
    "    im_noise_fft = fft2(im)\n",
    "    im_noise_fft_mag = np.abs(im_noise_fft / (h * w) ** .5)\n",
    "\n",
    "    im_noise_fft_mag_noise = wiener_adaptive(im_noise_fft_mag, noise_var)\n",
    "\n",
    "    zeros_y, zeros_x = np.nonzero(im_noise_fft_mag == 0)\n",
    "\n",
    "    im_noise_fft_mag[zeros_y, zeros_x] = 1\n",
    "    im_noise_fft_mag_noise[zeros_y, zeros_x] = 0\n",
    "\n",
    "    im_noise_fft_filt = im_noise_fft * im_noise_fft_mag_noise / im_noise_fft_mag\n",
    "    im_noise_filt = np.real(ifft2(im_noise_fft_filt))\n",
    "\n",
    "    return im_noise_filt.astype(np.float32)\n",
    "\n",
    "\n",
    "def zero_mean(im: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ZeroMean called with the 'both' argument, as from Binghamton toolbox.\n",
    "    :param im: multidimensional array\n",
    "    :return: zero mean version of input im\n",
    "    \"\"\"\n",
    "    # Adapt the shape ---\n",
    "    if im.ndim == 2:\n",
    "        im.shape += (1,)\n",
    "\n",
    "    h, w, ch = im.shape\n",
    "\n",
    "    # Subtract the 2D mean from each color channel ---\n",
    "    ch_mean = im.mean(axis=0).mean(axis=0)\n",
    "    ch_mean.shape = (1, 1, ch)\n",
    "    i_zm = im - ch_mean\n",
    "\n",
    "    # Compute the 1D mean along each row and each column, then subtract ---\n",
    "    row_mean = i_zm.mean(axis=1)\n",
    "    col_mean = i_zm.mean(axis=0)\n",
    "\n",
    "    row_mean.shape = (h, 1, ch)\n",
    "    col_mean.shape = (1, w, ch)\n",
    "\n",
    "    i_zm_r = i_zm - row_mean\n",
    "    i_zm_rc = i_zm_r - col_mean\n",
    "\n",
    "    # Restore the shape ---\n",
    "    if im.shape[2] == 1:\n",
    "        i_zm_rc.shape = im.shape[:2]\n",
    "\n",
    "    return i_zm_rc\n",
    "\n",
    "\n",
    "def zero_mean_total(im: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ZeroMeanTotal as from Binghamton toolbox.\n",
    "    :param im: multidimensional array\n",
    "    :return: zero mean version of input im\n",
    "    \"\"\"\n",
    "    im[0::2, 0::2] = zero_mean(im[0::2, 0::2])\n",
    "    im[1::2, 0::2] = zero_mean(im[1::2, 0::2])\n",
    "    im[0::2, 1::2] = zero_mean(im[0::2, 1::2])\n",
    "    im[1::2, 1::2] = zero_mean(im[1::2, 1::2])\n",
    "    return im\n",
    "\n",
    "\n",
    "def rgb2gray(im: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    RGB to gray as from Binghamton toolbox.\n",
    "    :param im: multidimensional array\n",
    "    :return: grayscale version of input im\n",
    "    \"\"\"\n",
    "    rgb2gray_vector = np.asarray([0.29893602, 0.58704307, 0.11402090]).astype(np.float32)\n",
    "    rgb2gray_vector.shape = (3, 1)\n",
    "\n",
    "    if im.ndim == 2:\n",
    "        im_gray = np.copy(im)\n",
    "    elif im.shape[2] == 1:\n",
    "        im_gray = np.copy(im[:, :, 0])\n",
    "    elif im.shape[2] == 3:\n",
    "        w, h = im.shape[:2]\n",
    "        im = np.reshape(im, (w * h, 3))\n",
    "        im_gray = np.dot(im, rgb2gray_vector)\n",
    "        im_gray.shape = (w, h)\n",
    "    else:\n",
    "        raise ValueError('Input image must have 1 or 3 channels')\n",
    "\n",
    "    return im_gray.astype(np.float32)\n",
    "\n",
    "\n",
    "def threshold(wlet_coeff_energy_avg: np.ndarray, noise_var: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Noise variance theshold as from Binghamton toolbox.\n",
    "    :param wlet_coeff_energy_avg:\n",
    "    :param noise_var:\n",
    "    :return: noise variance threshold\n",
    "    \"\"\"\n",
    "    res = wlet_coeff_energy_avg - noise_var\n",
    "    return (res + np.abs(res)) / 2\n",
    "\n",
    "\n",
    "def wiener_adaptive(x: np.ndarray, noise_var: float, **kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    WaveNoise as from Binghamton toolbox.\n",
    "    Wiener adaptive flter aimed at extracting the noise component\n",
    "    For each input pixel the average variance over a neighborhoods of different window sizes is first computed.\n",
    "    The smaller average variance is taken into account when filtering according to Wiener.\n",
    "    :param x: 2D matrix\n",
    "    :param noise_var: Power spectral density of the noise we wish to extract (S)\n",
    "    :param window_size_list: list of window sizes\n",
    "    :return: wiener filtered version of input x\n",
    "    \"\"\"\n",
    "    window_size_list = list(kwargs.pop('window_size_list', [3, 5, 7, 9]))\n",
    "\n",
    "    energy = x ** 2\n",
    "\n",
    "    avg_win_energy = np.zeros(x.shape + (len(window_size_list),))\n",
    "    for window_idx, window_size in enumerate(window_size_list):\n",
    "        avg_win_energy[:, :, window_idx] = filters.uniform_filter(energy,\n",
    "                                                                  window_size,\n",
    "                                                                  mode='constant')\n",
    "\n",
    "    coef_var = threshold(avg_win_energy, noise_var)\n",
    "    coef_var_min = np.min(coef_var, axis=2)\n",
    "\n",
    "    x = x * noise_var / (coef_var_min + noise_var)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def inten_scale(im: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    IntenScale as from Binghamton toolbox\n",
    "    :param im: type np.uint8\n",
    "    :return: intensity scaled version of input x\n",
    "    \"\"\"\n",
    "\n",
    "    assert (im.dtype == np.uint8)\n",
    "\n",
    "    T = 252\n",
    "    v = 6\n",
    "    out = np.exp(-1 * (im - T) ** 2 / v)\n",
    "    out[im < T] = im[im < T] / T\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def saturation(im: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Saturation as from Binghamton toolbox\n",
    "    :param im: type np.uint8\n",
    "    :return: saturation map from input im\n",
    "    \"\"\"\n",
    "    assert (im.dtype == np.uint8)\n",
    "\n",
    "    if im.ndim == 2:\n",
    "        im.shape += (1,)\n",
    "\n",
    "    h, w, ch = im.shape\n",
    "\n",
    "    if im.max() < 250:\n",
    "        return np.ones((h, w, ch))\n",
    "\n",
    "    im_h = im - np.roll(im, (0, 1), (0, 1))\n",
    "    im_v = im - np.roll(im, (1, 0), (0, 1))\n",
    "    satur_map = \\\n",
    "        np.bitwise_not(\n",
    "            np.bitwise_and(\n",
    "                np.bitwise_and(\n",
    "                    np.bitwise_and(\n",
    "                        im_h != 0, im_v != 0\n",
    "                    ), np.roll(im_h, (0, -1), (0, 1)) != 0\n",
    "                ), np.roll(im_v, (-1, 0), (0, 1)) != 0\n",
    "            )\n",
    "        )\n",
    "\n",
    "    max_ch = im.max(axis=0).max(axis=0)\n",
    "\n",
    "    for ch_idx, max_c in enumerate(max_ch):\n",
    "        if max_c > 250:\n",
    "            satur_map[:, :, ch_idx] = \\\n",
    "                np.bitwise_not(\n",
    "                    np.bitwise_and(\n",
    "                        im[:, :, ch_idx] == max_c, satur_map[:, :, ch_idx]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return satur_map\n",
    "\n",
    "\n",
    "def inten_sat_compact(args):\n",
    "    \"\"\"\n",
    "    Memory saving version of inten_scale followed by saturation. Useful for multiprocessing\n",
    "    :param args:\n",
    "    :return: intensity scale and saturation of input\n",
    "    \"\"\"\n",
    "    im = args[0]\n",
    "    return ((inten_scale(im) * saturation(im)) ** 2).astype(np.float32)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Cross-correlation functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def crosscorr_2d(k1: np.ndarray, k2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    PRNU 2D cross-correlation\n",
    "    :param k1: 2D matrix of size (h1,w1)\n",
    "    :param k2: 2D matrix of size (h2,w2)\n",
    "    :return: 2D matrix of size (max(h1,h2),max(w1,w2))\n",
    "    \"\"\"\n",
    "    assert (k1.ndim == 2)\n",
    "    assert (k2.ndim == 2)\n",
    "\n",
    "    max_height = max(k1.shape[0], k2.shape[0])\n",
    "    max_width = max(k1.shape[1], k2.shape[1])\n",
    "\n",
    "    k1 -= k1.flatten().mean()\n",
    "    k2 -= k2.flatten().mean()\n",
    "\n",
    "    k1 = np.pad(k1, [(0, max_height - k1.shape[0]), (0, max_width - k1.shape[1])], mode='constant', constant_values=0)\n",
    "    k2 = np.pad(k2, [(0, max_height - k2.shape[0]), (0, max_width - k2.shape[1])], mode='constant', constant_values=0)\n",
    "\n",
    "    k1_fft = fft2(k1, )\n",
    "    k2_fft = fft2(np.rot90(k2, 2), )\n",
    "\n",
    "    return np.real(ifft2(k1_fft * k2_fft)).astype(np.float32)\n",
    "\n",
    "\n",
    "def aligned_cc(k1: np.ndarray, k2: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Aligned PRNU cross-correlation\n",
    "    :param k1: (n1,nk) or (n1,nk1,nk2,...)\n",
    "    :param k2: (n2,nk) or (n2,nk1,nk2,...)\n",
    "    :return: {'cc':(n1,n2) cross-correlation matrix,'ncc':(n1,n2) normalized cross-correlation matrix}\n",
    "    \"\"\"\n",
    "\n",
    "    # Type cast\n",
    "    k1 = np.array(k1).astype(np.float32)\n",
    "    k2 = np.array(k2).astype(np.float32)\n",
    "\n",
    "    ndim1 = k1.ndim\n",
    "    ndim2 = k2.ndim\n",
    "    assert (ndim1 == ndim2)\n",
    "\n",
    "    k1 = np.ascontiguousarray(k1).reshape(k1.shape[0], -1)\n",
    "    k2 = np.ascontiguousarray(k2).reshape(k2.shape[0], -1)\n",
    "\n",
    "    assert (k1.shape[1] == k2.shape[1])\n",
    "\n",
    "    k1_norm = np.linalg.norm(k1, ord=2, axis=1, keepdims=True)\n",
    "    k2_norm = np.linalg.norm(k2, ord=2, axis=1, keepdims=True)\n",
    "\n",
    "    k2t = np.ascontiguousarray(k2.transpose())\n",
    "\n",
    "    cc = np.matmul(k1, k2t).astype(np.float32)\n",
    "    ncc = (cc / (k1_norm * k2_norm.transpose())).astype(np.float32)\n",
    "\n",
    "    return {'cc': cc, 'ncc': ncc}\n",
    "\n",
    "\n",
    "def pce(cc: np.ndarray, neigh_radius: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    PCE position and value\n",
    "    :param cc: as from crosscorr2d\n",
    "    :param neigh_radius: radius around the peak to be ignored while computing floor energy\n",
    "    :return: {'peak':(y,x), 'pce': peak to floor ratio, 'cc': cross-correlation value at peak position\n",
    "    \"\"\"\n",
    "    assert (cc.ndim == 2)\n",
    "    assert (isinstance(neigh_radius, int))\n",
    "\n",
    "    out = dict()\n",
    "\n",
    "    max_idx = np.argmax(cc.flatten())\n",
    "    max_y, max_x = np.unravel_index(max_idx, cc.shape)\n",
    "\n",
    "    peak_height = cc[max_y, max_x]\n",
    "\n",
    "    cc_nopeaks = cc.copy()\n",
    "    cc_nopeaks[max_y - neigh_radius:max_y + neigh_radius, max_x - neigh_radius:max_x + neigh_radius] = 0\n",
    "\n",
    "    pce_energy = np.mean(cc_nopeaks.flatten() ** 2)\n",
    "\n",
    "    out['peak'] = (max_y, max_x)\n",
    "    out['pce'] = (peak_height ** 2) / pce_energy * np.sign(peak_height)\n",
    "    out['cc'] = peak_height\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Statistical functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def stats(cc: np.ndarray, gt: np.ndarray, ) -> dict:\n",
    "    \"\"\"\n",
    "    Compute statistics\n",
    "    :param cc: cross-correlation or normalized cross-correlation matrix\n",
    "    :param gt: boolean multidimensional array representing groundtruth\n",
    "    :return: statistics dictionary\n",
    "    \"\"\"\n",
    "    assert (cc.shape == gt.shape)\n",
    "    assert (gt.dtype == np.bool)\n",
    "\n",
    "    assert (cc.shape == gt.shape)\n",
    "    assert (gt.dtype == np.bool)\n",
    "\n",
    "    fpr, tpr, th = roc_curve(gt.flatten(), cc.flatten())\n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    # EER\n",
    "    eer_idx = np.argmin((fpr - (1 - tpr)) ** 2, axis=0)\n",
    "    eer = float(fpr[eer_idx])\n",
    "\n",
    "    outdict = {\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'th': th,\n",
    "        'auc': auc_score,\n",
    "        'eer': eer,\n",
    "    }\n",
    "\n",
    "    return outdict\n",
    "\n",
    "\n",
    "def gt(l1: list or np.ndarray, l2: list or np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Determine the Ground Truth matrix given the labels\n",
    "    :param l1: fingerprints labels\n",
    "    :param l2: residuals labels\n",
    "    :return: groundtruth matrix\n",
    "    \"\"\"\n",
    "    l1 = np.array(l1)\n",
    "    l2 = np.array(l2)\n",
    "\n",
    "    assert (l1.ndim == 1)\n",
    "    assert (l2.ndim == 1)\n",
    "\n",
    "    gt_arr = np.zeros((len(l1), len(l2)), np.bool)\n",
    "\n",
    "    for l1idx, l1sample in enumerate(l1):\n",
    "        gt_arr[l1idx, l2 == l1sample] = True\n",
    "\n",
    "    return gt_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_prnu(camera_nr: int) -> np.ndarray:\n",
    "    path = 'C:\\\\Users\\\\rotar\\\\OneDrive\\\\Desktop\\\\Master\\\\UNITN\\\\Semester 1\\\\Multimedia Data Security\\\\2nd Competition\\\\dev-dataset\\\\'\n",
    "    index = '000'\n",
    "    noises = []\n",
    "    \n",
    "    for i in range(100):\n",
    "        index =\"%03d\" % (i+1)\n",
    "        im = Image.open(path + 'flat-camera-'+ str(camera_nr) + '\\\\flat_c'+ str(camera_nr) + '_' + index + '.tif')\n",
    "        imarray = np.array(im)\n",
    "        noise = noise_extract(imarray)\n",
    "        noises.append(noise)\n",
    "      \n",
    "    final = np.mean(noises,0)\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prnu1 = get_camera_prnu(1)\n",
    "prnu2 = get_camera_prnu(2)\n",
    "prnu3 = get_camera_prnu(3)\n",
    "prnu4 = get_camera_prnu(4)\n",
    "#prnu1_img = Image.fromarray(prnu1, 'RGB')\n",
    "#prnu1_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('store.pckl', 'wb')\n",
    "prnus = [prnu1, prnu2, prnu3, prnu4]\n",
    "pickle.dump(prnus, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1c64a640b2c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'store.pckl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprev_prnus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprnu1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_prnus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprnu2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_prnus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file = open('store.pckl', 'rb')\n",
    "prev_prnus = pickle.load(file)\n",
    "prnu1 = prev_prnus[0]\n",
    "prnu2 = prev_prnus[1]\n",
    "prnu3 = prev_prnus[2]\n",
    "prnu4 = prev_prnus[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def mean2(x):\n",
    "    y = np.sum(x) / np.size(x);\n",
    "    return y\n",
    "\n",
    "def corr2(a,b):\n",
    "    a = a - mean2(a)\n",
    "    b = b - mean2(b)\n",
    "\n",
    "    r = (a*b).sum() / math.sqrt((a*a).sum() * (b*b).sum());\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(prnu : np.ndarray or list, noise: np.ndarray or list) -> np.ndarray:\n",
    "    \n",
    "    diff_map = numpy.zeros_like(prnu)\n",
    "    for i in range(len(prnu)):\n",
    "        for j in range(len(prnu[0])):\n",
    "            diff_map[i][j] = round(abs(prnu[i][j] - noise[i][j]))\n",
    "            \n",
    "    return diff_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#im = Image.open('C:\\\\Users\\\\rotar\\\\OneDrive\\\\Desktop\\\\Master\\\\UNITN\\\\Semester 1\\\\Multimedia Data Security\\\\2nd Competition\\\\dev-dataset\\\\dev-dataset-forged\\\\dev_0004.tif')\n",
    "\n",
    "im = Image.open('C:\\\\Users\\\\rotar\\\\OneDrive\\\\Desktop\\\\Master\\\\UNITN\\\\Semester 1\\\\Multimedia Data Security\\\\2nd Competition\\\\dev-dataset\\\\dev-dataset-forged\\\\dev_0029.tif')\n",
    "\n",
    "\n",
    "imarray = np.array(im)\n",
    "\n",
    "noise = noise_extract(imarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0005358552605372079\n",
      "0.00020984400218344797\n",
      "0.001305504048464593\n",
      "0.09469966165421587\n"
     ]
    }
   ],
   "source": [
    "print(corr2(noise, prnu1))\n",
    "print(corr2(noise, prnu2))\n",
    "print(corr2(noise, prnu3))\n",
    "print(corr2(noise, prnu4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffs1 = get_map(noise[:,:,1], prnu1[:,:,1])\n",
    "#diffs2 = get_map(noise[:,:,1], prnu2[:,:,1])\n",
    "#diffs3 = get_map(noise[:,:,1], prnu3[:,:,1])\n",
    "diffs41 = get_map(noise[:,:,0], prnu4[:,:,0])\n",
    "diffs42 = get_map(noise[:,:,1], prnu4[:,:,1])\n",
    "diffs43 = get_map(noise[:,:,2], prnu4[:,:,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs4 = numpy.zeros_like(diffs41)\n",
    "for i in range(len(diffs41)):\n",
    "        for j in range(len(diffs41[0])):\n",
    "            if (diffs41[i][j] + diffs42[i][j] + diffs43[i][j]) >7:\n",
    "                diffs4[i][j] = 255\n",
    "            else:\n",
    "                diffs4[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inside(i: int, j: int, rows: int, cols: int):\n",
    "    if (i>=0 and j >=0 and i<rows and j<cols): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_segment(prnu : np.ndarray or list, noise: np.ndarray or list, rows: int, cols: int, thr: float, clear: bool) -> np.ndarray:\n",
    "    row_inc = prnu.shape[0]/rows\n",
    "    col_inc = prnu.shape[1]/cols\n",
    "    \n",
    "    avg = numpy.average(numpy.absolute(prnu-noise))\n",
    "    \n",
    "    diff_map = diff_map = numpy.zeros_like(prnu, np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            i1 = int(i*row_inc)\n",
    "            i2 = int((i+1)*row_inc)\n",
    "            j1 = int(j*col_inc)\n",
    "            j2 = int((j+1)*col_inc)\n",
    "            \n",
    "            m = numpy.mean(numpy.absolute(prnu[i1:i2, j1:j2] - noise[i1:i2, j1:j2]))\n",
    "            if(m > avg*1.1):\n",
    "                diff_map[i1:i2, j1:j2].fill(255)\n",
    "            else:\n",
    "                diff_map[i1:i2, j1:j2].fill(0)\n",
    "                \n",
    "    if(clear):\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                i1 = int(i*row_inc)\n",
    "                i2 = int((i+1)*row_inc)\n",
    "                j1 = int(j*col_inc)\n",
    "                j2 = int((j+1)*col_inc)\n",
    "\n",
    "                if(is_inside(i1-1,j1, prnu.shape[0], prnu.shape[1]) and diff_map[i1-1][j1] != diff_map[i1][j1] and \n",
    "                   is_inside(i2+1,j1, prnu.shape[0], prnu.shape[1]) and diff_map[i2+1][j1] != diff_map[i1][j1] and \n",
    "                   is_inside(i1,j2+1, prnu.shape[0], prnu.shape[1]) and diff_map[i1][j2+1] != diff_map[i1][j1] and \n",
    "                   is_inside(i1,j1-1, prnu.shape[0], prnu.shape[1]) and diff_map[i1][j1-1] != diff_map[i1][j1]):\n",
    "                    diff_map[i1:i2, j1:j2].fill(abs(diff_map[i1][j1] - 255))\n",
    "            \n",
    "    return diff_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "diff = get_map_segment(noise[:,:,1], prnu4[:,:,1], 200, 300, 1, True )\n",
    "#diff = cv2.medianBlur(diff, 29)\n",
    "img = Image.fromarray(diff)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((29,29),np.uint8)\n",
    "#erosion = cv2.erode(diff,kernel,iterations = 2)\n",
    "erosion = cv2.dilate(diff,kernel,iterations = 3)\n",
    "erosion = cv2.erode(erosion,kernel,iterations = 3)\n",
    "img = Image.fromarray(erosion)\n",
    "img.show()\n",
    "#cv2.imshow(\"res\", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def f_measure(map_gt,map_est):\n",
    "    if not map_gt.shape == map_est.shape:\n",
    "        print('The compared maps must have the same size')\n",
    "\n",
    "    # Vectorize maps\n",
    "    map_gt = np.ndarray.flatten(map_gt)\n",
    "    map_est = np.ndarray.flatten(map_est)\n",
    "\n",
    "    # Number of pixels\n",
    "    N = map_gt.size\n",
    "    # Indices of forged pixels in the ground truth\n",
    "    i_pos = np.where(map_gt == 1)\n",
    "    # Number of forged pixels in the ground truth\n",
    "    n_pos = map_gt[i_pos].shape[0]\n",
    "\n",
    "    # True Positive Rate: fraction of forged pixels correctly identified as forged\n",
    "    tp = np.where(map_gt[i_pos]==map_est[i_pos])[0].shape[0]\n",
    "    tpr = tp / n_pos\n",
    "    # False Negative Rate: fraction of forged pixels wrongly identified as non-forged\n",
    "    fn = n_pos-tp\n",
    "    fnr = fn / n_pos\n",
    "    # False Positive Rate: fraction of non-forged pixels wrongly identified as forged\n",
    "    # Indices of non-forged pixels in the ground truth\n",
    "    i_neg = np.where(map_gt == 0)\n",
    "    fp = np.where(map_est[i_neg]==1)[0].shape[0]\n",
    "    fpr = fp / (N-n_pos)\n",
    "\n",
    "    F = 2*tp / (2*tp+fn+fp)\n",
    "\n",
    "    return F, tp, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46894358668461766\n"
     ]
    }
   ],
   "source": [
    "map_gt = imageio.imread('C:\\\\Users\\\\rotar\\\\OneDrive\\\\Desktop\\\\Master\\\\UNITN\\\\Semester 1\\\\Multimedia Data Security\\\\2nd Competition\\\\dev-dataset\\\\dev-dataset-maps\\\\dev_0027.bmp')\n",
    "map_gt = np.array(map_gt/255,dtype=np.uint8)\n",
    "\n",
    "map_est = np.array(erosion/255,dtype=np.uint8)\n",
    "\n",
    "F,_,_,_ = f_measure(map_gt,map_est)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
